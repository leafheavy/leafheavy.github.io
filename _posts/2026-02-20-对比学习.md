---
title: "对比学习论文串烧"
date: 2024-02-16
permalink: /posts/2024/02/对比学习论文串烧/
tags:
  - 论文阅读
  - 对比学习
category: tech
# 关键点: 开启 LaTeX 数学公式支持
mathjax: true
---

# 对比学习论文串烧

**本质思想:** 利用数据对 (positive/negative pairs) 进行无监督/自监督学习, 在 feature space 上, 将同个类别的数据 (positive) 拉近, 不属于同个类别 (negative) 的推远.

**自监督:** 通过设计代理任务 (Auxiliary Task) 产生监督信号, 进而指导模型学习. 

- 代理任务: 旨在**帮助模型学习到更良好表征** (representation) 的**不被重点关注**的任务.

综上, 对比学习需要解决的问题也就很清晰了:

- 如何设计代理任务?
- 如何构造正负数据对? 即: 如何定义正数据对? 如何定义负数据对?
- 如何学习? 即: Contrastive Loss 实现 “拉近推远” 的效果? 更进一步, 如何设计 Contrastive Loss?

接下来笔者将对比学习领域的经典论文进行笔记整理, 其中知识点主要来自b站视频 [对比学习论文讲解1](https://www.bilibili.com/video/BV1C3411s7t9/?spm_id_from=333.1007.top_right_bar_window_history.content.click&vd_source=a310f211c2101503fd8e3dc63176607c), [对比学习论文讲解2](https://www.bilibili.com/video/BV1C3411s7t9/?spm_id_from=333.1007.top_right_bar_window_history.content.click&vd_source=a310f211c2101503fd8e3dc63176607c); 同时还有: 笔者对额外相关材料的查阅以及对论文原文的粗浅理解. [沐神组织的这个读论文栏目](https://space.bilibili.com/1567748478/upload/video)虽然时间已比较久远, 但是质量非常高, 是非常不错的学习材料.

<span id='sec:instdisc'></span>

## [InstDisc](https://openaccess.thecvf.com/content_cvpr_2018/papers/Wu_Unsupervised_Feature_Learning_CVPR_2018_paper.pdf)

### 如何设计代理任务? 

该篇论文首次提出了[个体判别任务](https://zhida.zhihu.com/search/3715216596552261941). 该任务的核心思想是: 将每个独立个体作为一类进行分类任务.
![InstDisc Motivation](/images/blogs/对比学习论文串烧/InstDisc_motivation.png)

如上图所示, InstDisc 作者的 insight 是: 图片本身的相似性影响了分类器预测类别概率, **分类器预测类别的概率并不依赖于标签信息.**
- 举个例子: 判断此时一张豹子照片的类别. 
  - 由于猎豹, 雪豹等豹类图片本身相似, logits 在这几类上分的概率也较高;
  - 豹子和船, 手推车, 书架不相似, 自然 logits 分的的概率均较低. 

标签依赖性剥离, 促使作者的目光自然延申至 unsupervised learning 领域, 聚焦于如何挖掘出图片本身的信息, 即输入本身的比较. 更进一步, 则是**将每个输入作为类别**进行比较, 这也是个体判别任务提出的思维链.

> 上述思维链仅是笔者对 InstDisc 工作的个人见解与整合.

现在, 我们基于 insight 推导出代理任务的形式. 接下来自然需要解决另外两个本质问题. 

### 如何构造正负数据对?

### 如何设计 Contrastive Loss?

鉴于传统 $\text{softmax}$ 操作:

$$
\begin{align}
P(i|\boldsymbol{v})=\frac{\exp(\boldsymbol{w}_i^{\top} \boldsymbol{v})}{\sum_{j=1}^n \exp(\boldsymbol{w}_j^{\top} \boldsymbol{v})},
\end{align}
$$

其中, $\boldsymbol{v}=f_{\theta}(x)$ 为输入 $x$ 的特征. $\boldsymbol{w}_i$ 表示第 $i$-th 类别所对应的分类器权重, 也可以理解为: 第 $i$-th 类别的原型 (prototype). 我们不难发现, 传统 $\text{softmax}$ 操作无法直接比较输入 ($x$, 也是 $\boldsymbol{v}$). 因此作者作出改进:

$$
\begin{align}
P(i|\boldsymbol{v})=\frac{\exp(\boldsymbol{v}_i^{\top} \boldsymbol{v}/\tau)}{\sum_{j=1}^n \exp(\boldsymbol{v}_j^{\top} \boldsymbol{v}/\tau)},
\end{align}
$$

其中, $\boldsymbol{v}=f_{\theta}(x_i)$ 是 $\theta$ 在不断更新过程中, 模型 $f_{\theta}$ 输出的经过 $\ell_2$ 归一化的特征, **务必和直接从 Memory Bank 这个历史数组中得到的 $v_i$ 区分开**; 温度系数 $\tau$, 是用来调控 logits 的分布形状, 需要结合具体任务调参. 最终即可得到在对比学习领域经典的损失函数 InfoNCE. 需要注意的是, 最先给出 InfoNCE 损失函数并不来自于该项工作? 但是殊途同归.

在有监督学习中, $\text{softmax}$ 操作分母项中的 $K$ 是数据集类别数. 举个例子, 在 $\text{ImageNet}$ 上进行训练时, $K=1000$. 而在个体判别任务上, $K$ 不再是 $1000$, 而是恐怖的百万数量级, 这会导致 $\text{softmax}$ 操作极其敏感以及耗时耗力. 因此这里的 $K$ 我们是采样得到的负样本数量.

$$
\begin{align} \label{eq:infonce_loss}
J(\theta) = -\sum_{i=1}^{n} \log P(i|f_{\theta}(x_i))
\end{align}
$$



## [MoCo](https://openaccess.thecvf.com/content_CVPR_2020/papers/He_Momentum_Contrast_for_Unsupervised_Visual_Representation_Learning_CVPR_2020_paper.pdf)

将对比学习抽象为字典查找 (dictionary look-up):

- 正样本对：$\lbrace x_i^{\text{anch}}, x_i^{\text{pos}} \rbrace$；负样本对：$\lbrace x_i^{\text{anch}}, x_j^{\text{neg}} \rbrace,\ \forall i \neq j$.

- 将 $x_i^{\text{anch}}$ 视作查询 (query): $x^{\text{query}}$; 将正/负样本组织成为字典 (的 key): $\lbrace x_i^{\text{key}} \rbrace_{i=0}^{N}$.


| 核心假设          | 对假设的直觉                           | MoCo 做出的对应改进             |
| ----------------- | -------------------------------------- | ------------------------------- |
| 字典要大          | 足够充分的数据确保对原始类别的特征涵盖 | 使用队列存储 key fearture       |
| 编码器要一致/相近 | 保证了对比过程中的 "可比性"            | 引入动量编码器提取 key fearture |

![MoCo 流程图](/images/blogs/对比学习论文串烧/image-20260219120333622.png)

接下来顺一下思维链: 

![改进思维链](/images/blogs/对比学习论文串烧/改进的思维链.png)

接下来就是将改进塞入对比学习的框架, 即解决三种本质问题:

- **设计代理任务:** MoCo 和 [InstDisc](#sec:instdisc) 保持一致, 选择个体判别任务.

- **构造正负数据对:** 由代理任务自然可得, 正样本对是同张图片的多个变换; 负样本对则是不同图片. 在原文中还涉及到锚点 (Anchor), 其表示的是原始图像.

- **设计 Contrastive Loss:** MoCo 基于 dictionary look-up 抽象, 指出 Contrastive Loss 的设计原则即为: whose value is low when $q$ is similar to its positive key $k_+$ and dissimilar to all other keys (considered negative keys for $q$). 最终 MoCo 选择了 InfoNCE 损失函数, 如下所示.

$$
\begin{align}
\mathcal{L}_{q} = -\log \frac{\exp(q\cdot k_{+}/\tau)}{\exp(q\cdot k_{+}/\tau) + \sum_{i=1}^{K} \exp(q\cdot k_{i}/\tau)}.
\end{align}
$$

> 详细分析见 \ref{eq:infonce_loss}

## 不定时更新中...

---

>## Reference
>
>[1] [MoCo 论文精读](https://www.bilibili.com/video/BV1C3411s7t9?spm_id_from=333.788.videopod.sections&vd_source=a310f211c2101503fd8e3dc63176607c)
>
> [2] [MoCo 原文](https://openaccess.thecvf.com/content_CVPR_2020/papers/He_Momentum_Contrast_for_Unsupervised_Visual_Representation_Learning_CVPR_2020_paper.pdf)